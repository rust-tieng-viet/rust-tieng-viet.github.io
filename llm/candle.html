<!DOCTYPE HTML>
<html lang="vi" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Candle - Minimalist ML Framework - Rust Tiếng Việt</title>


        <!-- Custom HTML head -->
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-88RKF7DLPY"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
        
          gtag('config', 'G-88RKF7DLPY');
        </script>
        
        <!-- pageview.js -->
        <script>
          !function(e,n,t){e.onload=function(){
          let e=n.createElement("script");
          e.src=t,n.body.appendChild(e)}}
          (window,document,"https://pageview.duyet.net/pageview.js");
        </script>
        
        <script async src="https://seline.duyet.workers.dev/seline.js" data-api-host="https://seline.duyet.workers.dev" data-token="d7c8002f8e40139"></script>
        <script async src="https://cm43xj8zd00093b619ak2zfuc.d.jitsu.com/p.js"></script>

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Rust Tiếng Việt</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/rust-tieng-viet/rust-tieng-viet.github.io" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/rust-tieng-viet/rust-tieng-viet.github.io/edit/main/src/llm/candle.md" title="Suggest an edit" aria-label="Suggest an edit" rel="edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="candle---minimalist-ml-framework"><a class="header" href="#candle---minimalist-ml-framework">Candle - Minimalist ML Framework</a></h1>
<p><a href="https://github.com/huggingface/candle">Candle</a> là một minimalist machine learning framework cho Rust được phát triển bởi Hugging Face. Candle được thiết kế để đơn giản, nhanh, và dễ sử dụng cho cả CPU và GPU inference.</p>
<h2 id="Đặc-điểm-chính"><a class="header" href="#Đặc-điểm-chính">Đặc điểm chính</a></h2>
<h3 id="1-minimal-và-performant"><a class="header" href="#1-minimal-và-performant">1. Minimal và Performant</a></h3>
<p>Candle focus vào simplicity và performance:</p>
<ul>
<li><strong>Lightweight</strong>: Không có heavy dependencies</li>
<li><strong>Fast</strong>: Tối ưu cho cả CPU và GPU</li>
<li><strong>Simple API</strong>: Dễ học và sử dụng</li>
<li><strong>No Python required</strong>: Pure Rust implementation</li>
</ul>
<h3 id="2-hardware-support"><a class="header" href="#2-hardware-support">2. Hardware Support</a></h3>
<p>Candle hỗ trợ nhiều backends:</p>
<ul>
<li><strong>CPU</strong>: Optimized CPU operations</li>
<li><strong>CUDA</strong>: NVIDIA GPU support</li>
<li><strong>Metal</strong>: Apple Silicon (M1/M2/M3) support</li>
<li><strong>WebGPU</strong>: Browser-based inference</li>
</ul>
<h3 id="3-model-support"><a class="header" href="#3-model-support">3. Model Support</a></h3>
<p>Hỗ trợ các popular model architectures:</p>
<ul>
<li><strong>Transformers</strong>: BERT, GPT, T5, etc.</li>
<li><strong>Vision</strong>: ResNet, ViT, CLIP</li>
<li><strong>Audio</strong>: Whisper (speech-to-text)</li>
<li><strong>Multimodal</strong>: CLIP, BLIP</li>
<li><strong>LLMs</strong>: Llama, Mistral, Phi</li>
</ul>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>Thêm vào <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
candle-core = "0.4.0"
candle-nn = "0.4.0"
candle-transformers = "0.4.0"

# Optional: CUDA support
candle-cuda = "0.4.0"

# Optional: Metal support (Apple Silicon)
candle-metal = "0.4.0"
</code></pre>
<h2 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h2>
<h3 id="1-tensor-operations"><a class="header" href="#1-tensor-operations">1. Tensor Operations</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021">use candle_core::{Device, Tensor};

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Tạo tensor trên CPU
    let device = Device::Cpu;

    let a = Tensor::new(&amp;[1f32, 2., 3., 4.], &amp;device)?;
    let b = Tensor::new(&amp;[5f32, 6., 7., 8.], &amp;device)?;

    // Phép tính
    let sum = (&amp;a + &amp;b)?;
    let product = (&amp;a * &amp;b)?;

    println!("Sum: {:?}", sum.to_vec1::&lt;f32&gt;()?);
    println!("Product: {:?}", product.to_vec1::&lt;f32&gt;()?);

    Ok(())
}</code></pre></pre>
<h3 id="2-matrix-operations"><a class="header" href="#2-matrix-operations">2. Matrix Operations</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021">use candle_core::{Device, Tensor};

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;

    // Tạo matrices
    let a = Tensor::new(
        &amp;[[1f32, 2.], [3., 4.]],
        &amp;device
    )?;

    let b = Tensor::new(
        &amp;[[5f32, 6.], [7., 8.]],
        &amp;device
    )?;

    // Matrix multiplication
    let result = a.matmul(&amp;b)?;

    println!("Result: {:?}", result.to_vec2::&lt;f32&gt;()?);

    Ok(())
}</code></pre></pre>
<h2 id="running-llms-with-candle"><a class="header" href="#running-llms-with-candle">Running LLMs with Candle</a></h2>
<h3 id="1-llama-model-inference"><a class="header" href="#1-llama-model-inference">1. Llama Model Inference</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021">use candle_core::{Device, Tensor};
use candle_transformers::models::llama::{Llama, Config};
use candle_nn::VarBuilder;

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Load model
    let device = Device::cuda_if_available(0)?;

    let config = Config::config_7b_v2();
    let vb = VarBuilder::from_pth("model.safetensors", &amp;device)?;
    let mut model = Llama::load(vb, &amp;config)?;

    // Tokenize input
    let prompt = "The Rust programming language is";
    let tokens = tokenize(prompt)?;

    // Generate
    let mut output_tokens = tokens.clone();
    for _ in 0..50 {  // Generate 50 tokens
        let logits = model.forward(&amp;output_tokens)?;
        let next_token = sample(&amp;logits)?;
        output_tokens.push(next_token);
    }

    // Decode
    let generated_text = detokenize(&amp;output_tokens)?;
    println!("{}", generated_text);

    Ok(())
}</code></pre></pre>
<h3 id="2-whisper-speech-to-text"><a class="header" href="#2-whisper-speech-to-text">2. Whisper (Speech-to-Text)</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use candle_core::Device;
use candle_transformers::models::whisper::{self, Config, Model};

fn transcribe_audio(audio_path: &amp;str) -&gt; Result&lt;String, Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::cuda_if_available(0)?;

    // Load model
    let config = Config::tiny_en();
    let model = Model::load(&amp;config, &amp;device)?;

    // Load and preprocess audio
    let audio = load_audio(audio_path)?;
    let mel = audio_to_mel(&amp;audio)?;

    // Transcribe
    let tokens = model.decode(&amp;mel)?;
    let text = tokens_to_text(&amp;tokens)?;

    Ok(text)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-bert-embeddings"><a class="header" href="#3-bert-embeddings">3. BERT Embeddings</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use candle_core::{Device, Tensor};
use candle_transformers::models::bert::{BertModel, Config};

fn get_embeddings(text: &amp;str) -&gt; Result&lt;Tensor, Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;

    // Load BERT model
    let config = Config::default();
    let model = BertModel::load(&amp;config, &amp;device)?;

    // Tokenize
    let tokens = tokenize(text)?;
    let token_ids = Tensor::new(tokens.as_slice(), &amp;device)?;

    // Get embeddings
    let embeddings = model.forward(&amp;token_ids)?;

    Ok(embeddings)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-usage"><a class="header" href="#advanced-usage">Advanced Usage</a></h2>
<h3 id="1-gpu-acceleration"><a class="header" href="#1-gpu-acceleration">1. GPU Acceleration</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021">use candle_core::{Device, Tensor};

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Sử dụng CUDA nếu có
    let device = Device::cuda_if_available(0)?;

    // Hoặc explicitly chọn device
    let device = if cfg!(feature = "cuda") {
        Device::new_cuda(0)?
    } else if cfg!(feature = "metal") {
        Device::new_metal(0)?
    } else {
        Device::Cpu
    };

    let tensor = Tensor::randn(0f32, 1f32, (1000, 1000), &amp;device)?;

    println!("Running on: {:?}", device);

    Ok(())
}</code></pre></pre>
<h3 id="2-custom-models"><a class="header" href="#2-custom-models">2. Custom Models</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use candle_core::{Device, Tensor, Module};
use candle_nn::{Linear, VarBuilder, ops};

struct SimpleNN {
    fc1: Linear,
    fc2: Linear,
}

impl SimpleNN {
    fn new(vb: VarBuilder) -&gt; Result&lt;Self, Box&lt;dyn std::error::Error&gt;&gt; {
        let fc1 = candle_nn::linear(784, 128, vb.pp("fc1"))?;
        let fc2 = candle_nn::linear(128, 10, vb.pp("fc2"))?;

        Ok(Self { fc1, fc2 })
    }

    fn forward(&amp;self, x: &amp;Tensor) -&gt; Result&lt;Tensor, Box&lt;dyn std::error::Error&gt;&gt; {
        let x = self.fc1.forward(x)?;
        let x = x.relu()?;
        let x = self.fc2.forward(&amp;x)?;
        Ok(x)
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-quantization"><a class="header" href="#3-quantization">3. Quantization</a></h3>
<p>Candle hỗ trợ quantization để giảm model size và tăng tốc inference:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use candle_core::{Device, Tensor};
use candle_transformers::quantized_llama::ModelWeights;

fn load_quantized_model() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;

    // Load quantized model (4-bit, 8-bit)
    let model = ModelWeights::from_gguf(
        "llama-2-7b-Q4_K_M.gguf",
        &amp;device
    )?;

    // Model size nhỏ hơn rất nhiều
    // 7B model: ~14GB -&gt; ~4GB với Q4 quantization

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h2>
<h3 id="1-local-llm-inference"><a class="header" href="#1-local-llm-inference">1. Local LLM Inference</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use candle_transformers::models::quantized_llama::ModelWeights;

fn chat_with_local_llm(prompt: &amp;str) -&gt; Result&lt;String, Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;

    // Load quantized Llama
    let mut model = ModelWeights::from_gguf(
        "llama-2-7b-chat.Q4_K_M.gguf",
        &amp;device
    )?;

    // Generate response
    let response = model.generate(prompt, 512)?;

    Ok(response)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-image-classification"><a class="header" href="#2-image-classification">2. Image Classification</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use candle_transformers::models::resnet;

fn classify_image(image_path: &amp;str) -&gt; Result&lt;String, Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;

    // Load ResNet
    let model = resnet::resnet50(&amp;device)?;

    // Load and preprocess image
    let image = load_image(image_path)?;
    let tensor = preprocess_image(&amp;image)?;

    // Classify
    let logits = model.forward(&amp;tensor)?;
    let class = argmax(&amp;logits)?;

    Ok(imagenet_classes()[class].to_string())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-text-embeddings-for-rag"><a class="header" href="#3-text-embeddings-for-rag">3. Text Embeddings for RAG</a></h3>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use candle_transformers::models::bert;

fn generate_embeddings(texts: Vec&lt;&amp;str&gt;) -&gt; Result&lt;Vec&lt;Vec&lt;f32&gt;&gt;, Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;
    let model = bert::BertModel::load_default(&amp;device)?;

    let mut embeddings = Vec::new();

    for text in texts {
        let tokens = tokenize(text)?;
        let embedding = model.encode(&amp;tokens)?;
        embeddings.push(embedding.to_vec1()?);
    }

    Ok(embeddings)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-comparison"><a class="header" href="#performance-comparison">Performance Comparison</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Backend</th><th>Llama 7B Inference</th><th>Speedup</th></tr></thead><tbody>
<tr><td>CPU (Intel i9)</td><td>~2.5 tokens/s</td><td>1x</td></tr>
<tr><td>CUDA (RTX 4090)</td><td>~45 tokens/s</td><td>18x</td></tr>
<tr><td>Metal (M2 Max)</td><td>~25 tokens/s</td><td>10x</td></tr>
</tbody></table>
</div>
<p><em>Quantized models (Q4): ~2-3x faster with similar quality</em></p>
<h2 id="Ưu-điểm"><a class="header" href="#Ưu-điểm">Ưu điểm</a></h2>
<p>✅ <strong>Pure Rust</strong>: Không cần Python runtime
✅ <strong>Fast</strong>: Optimized cho performance
✅ <strong>Minimal</strong>: Ít dependencies, dễ build
✅ <strong>Cross-platform</strong>: CPU, CUDA, Metal, WebGPU
✅ <strong>Model Support</strong>: Nhiều popular architectures
✅ <strong>Quantization</strong>: Giảm memory usage</p>
<h2 id="nhược-điểm"><a class="header" href="#nhược-điểm">Nhược điểm</a></h2>
<p>⚠️ <strong>Younger Ecosystem</strong>: Ít mature hơn PyTorch/TensorFlow
⚠️ <strong>Fewer Models</strong>: Không nhiều pre-trained models như Python
⚠️ <strong>Training</strong>: Chủ yếu focus vào inference</p>
<h2 id="khi-nào-nên-dùng-candle"><a class="header" href="#khi-nào-nên-dùng-candle">Khi nào nên dùng Candle?</a></h2>
<p><strong>Nên dùng Candle khi:</strong></p>
<ul>
<li>Muốn run models locally không cần Python</li>
<li>Cần fast inference với low latency</li>
<li>Deploy trên edge devices</li>
<li>Xây dựng production services trong Rust</li>
<li>Muốn single binary deployment</li>
</ul>
<p><strong>Có thể dùng Python frameworks khi:</strong></p>
<ul>
<li>Training models (PyTorch, TensorFlow tốt hơn)</li>
<li>Cần extensive model zoo</li>
<li>Team đã thành thạo Python ML stack</li>
</ul>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/huggingface/candle">https://github.com/huggingface/candle</a></li>
<li><strong>Examples</strong>: <a href="https://github.com/huggingface/candle/tree/main/candle-examples">Candle Examples</a></li>
<li><strong>Documentation</strong>: <a href="https://docs.rs/candle-core">docs.rs/candle-core</a></li>
</ul>
<h2 id="kết-luận"><a class="header" href="#kết-luận">Kết luận</a></h2>
<p>Candle là một excellent choice để run ML models, đặc biệt là LLMs, trong Rust. Với pure Rust implementation, cross-platform support, và focus vào performance, Candle giúp bạn xây dựng fast và reliable ML inference systems mà không cần Python dependency.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../llm/llm-crate.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../llm/ai-agents-workflows.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../llm/llm-crate.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../llm/ai-agents-workflows.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../editor.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
